{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Projeto de Mestrado","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o do meu projeto de mestrado. Este espa\u00e7o organiza, acompanha e documenta todas as etapas do desenvolvimento do trabalho, de forma clara, versionada e acess\u00edvel.</p>"},{"location":"#objetivo","title":"\ud83c\udfaf Objetivo","text":"<p>Este projeto de mestrado tem como foco principal:</p> <p>Este trabalho tem como objetivo avaliar e comparar o desempenho de diferentes modelos de Machine Learning na tarefa de classifica\u00e7\u00e3o de estudos em Revis\u00f5es Sistem\u00e1ticas da Literatura (RSL), com vistas a identificar os modelos mais eficazes e contribuir para o desenvolvimento de uma base metodol\u00f3gica s\u00f3lida que subsidie an\u00e1lises automatizadas futuras nesse dom\u00ednio.</p> <p>Al\u00e9m disso, busca-se manter um processo organizado e transparente durante o desenvolvimento, com registros frequentes de progresso e decis\u00f5es.</p>"},{"location":"#estrutura-da-documentacao","title":"\ud83d\udcc2 Estrutura da Documenta\u00e7\u00e3o","text":"<ul> <li>\ud83d\udccc RFCs \u2014 Propostas formais de decis\u00f5es t\u00e9cnicas, metodol\u00f3gicas ou estruturais.</li> <li>\ud83d\udcc8 Relat\u00f3rios \u2014 Acompanhamento de progresso, experimentos e an\u00e1lises.</li> <li>\ud83e\udde0 Outros \u2014 Ideias soltas, cronograma, brainstorms e notas gerais.</li> </ul>"},{"location":"#andamento","title":"\ud83d\udcc5 Andamento","text":"<p>O andamento do projeto pode ser acompanhado pelo cronograma atualizado e pelos relat\u00f3rios semanais ou mensais dispon\u00edveis na se\u00e7\u00e3o de Relat\u00f3rios.</p>"},{"location":"#tecnologias-e-ferramentas","title":"\ud83d\udee0\ufe0f Tecnologias e Ferramentas","text":"<ul> <li>MkDocs</li> <li>Material for MkDocs</li> <li>Python, Jupyter Notebooks, ferramentas de NLP, etc.</li> </ul>"},{"location":"#links-rapidos","title":"Links R\u00e1pidos","text":"<ul> <li>Documento Overleaf</li> <li>Google Drive Arquivos</li> <li>Google Sites Mestrado</li> </ul> <p>Este site \u00e9 atualizado continuamente conforme o progresso do projeto.</p>"},{"location":"others/","title":"Outros","text":""},{"location":"others/schedule/","title":"Cronograma","text":"<p>Este \u00e9 o cronograma planejado para as principais atividades do mestrado, incluindo reda\u00e7\u00e3o dos cap\u00edtulos, etapas de pesquisa e prepara\u00e7\u00e3o da apresenta\u00e7\u00e3o final.</p> <p>A imagem abaixo apresenta uma vis\u00e3o geral m\u00eas a m\u00eas, do andamento esperado de cada tarefa:</p>"},{"location":"others/schedule/#descricao-das-etapas","title":"\ud83e\uddfe Descri\u00e7\u00e3o das Etapas","text":""},{"location":"others/schedule/#1-capitulos-redacao","title":"1. Cap\u00edtulos (Reda\u00e7\u00e3o)","text":"<ul> <li>Cap 1 a Cap 4: redigidos entre junho e agosto.</li> <li>Cap 5: planejado para outubro.</li> <li>Cap 6: in\u00edcio no final de outubro, com entrega em novembro.</li> <li>Cap 7: n\u00e3o planejado at\u00e9 dezembro (campo em branco).</li> </ul>"},{"location":"others/schedule/#2-pesquisa","title":"2. Pesquisa","text":"<ul> <li>Coleta de Dados: agosto.</li> <li>Processamento de Dados: entre agosto e setembro.</li> <li>Adi\u00e7\u00e3o de Modelos: come\u00e7a no final de agosto e se estende por setembro.</li> <li>Separa\u00e7\u00e3o de Resultados: durante todo o m\u00eas de setembro.</li> </ul>"},{"location":"others/schedule/#3-apresentacao","title":"3. Apresenta\u00e7\u00e3o","text":"<ul> <li>Apresenta\u00e7\u00e3o Final: est\u00e1 prevista para o in\u00edcio de novembro e vai at\u00e9 a primeira semana de dezembro.</li> </ul>"},{"location":"others/schedule/#observacoes","title":"\ud83d\uddd3\ufe0f Observa\u00e7\u00f5es","text":"<ul> <li>Setores destacados em amarelo indicam prazos cr\u00edticos em novembro.</li> <li>Setores em vermelho claro e escuro indicam o fim do cronograma e entrega final.</li> <li>O cronograma permite identificar poss\u00edveis sobreposi\u00e7\u00f5es e gargalos, especialmente nas etapas finais.</li> </ul>"},{"location":"reports/","title":"Relat\u00f3rios","text":"<p>Esta se\u00e7\u00e3o \u00e9 dedicada aos relat\u00f3rios gerados ao longo do desenvolvimento do projeto de mestrado. Os relat\u00f3rios t\u00eam como objetivo registrar o progresso das atividades, experimentos realizados, an\u00e1lises de resultados e qualquer outro tipo de informa\u00e7\u00e3o relevante para o acompanhamento do trabalho.</p>"},{"location":"reports/#objetivo-dos-relatorios","title":"Objetivo dos Relat\u00f3rios","text":"<p>Os relat\u00f3rios servem como uma forma de:</p> <ul> <li>Documentar o andamento das tarefas de pesquisa.</li> <li>Registrar experimentos executados, incluindo configura\u00e7\u00f5es, m\u00e9tricas e resultados.</li> <li>Apontar dificuldades encontradas e decis\u00f5es tomadas.</li> <li>Compartilhar status com o orientador ou com o grupo de pesquisa.</li> <li>Facilitar o acompanhamento cont\u00ednuo e a organiza\u00e7\u00e3o do projeto.</li> </ul>"},{"location":"reports/#frequencia","title":"Frequ\u00eancia","text":"<p>A cria\u00e7\u00e3o dos relat\u00f3rios \u00e9 flex\u00edvel. Eles podem ser:</p> <ul> <li>Mensais \u2013 para uma vis\u00e3o geral do andamento no m\u00eas.</li> <li>Semanais \u2013 \u00fateis em per\u00edodos mais intensivos de trabalho.</li> <li>Pontuais \u2013 criados ap\u00f3s eventos ou marcos importantes, como:</li> <li>Finaliza\u00e7\u00e3o de um experimento,</li> <li>Discuss\u00e3o com o orientador,</li> <li>An\u00e1lise estat\u00edstica conclu\u00edda.</li> </ul>"},{"location":"reports/#conteudo-tipico-de-um-relatorio","title":"Conte\u00fado t\u00edpico de um relat\u00f3rio","text":"<p>Cada relat\u00f3rio pode conter:</p> <ul> <li>Data de cria\u00e7\u00e3o</li> <li>Descri\u00e7\u00e3o das atividades realizadas</li> <li>Objetivos da semana/m\u00eas</li> <li>Experimentos executados</li> <li>Resultados e gr\u00e1ficos</li> <li>Problemas encontrados</li> <li>Pr\u00f3ximos passos</li> </ul> <p>Info</p> <p>Os relat\u00f3rios n\u00e3o precisam seguir um modelo r\u00edgido, mas devem ser objetivos e \u00fateis para consulta futura.</p>"},{"location":"reports/status/status_report_2025_06_29/","title":"Status Report - 29/06/2025","text":""},{"location":"reports/status/status_report_2025_06_29/#intruducao","title":"Intrudu\u00e7\u00e3o","text":"<p>Este relat\u00f3rio de status tem como objetivo documentar o progresso realizado no projeto de mestrado ao longo do m\u00eas de Junho de 2025, com foco especial no per\u00edodo entre os dias 04/06 e 29/06. As atividades desenvolvidas neste intervalo concentram-se no estudo aprofundado, replica\u00e7\u00e3o parcial e an\u00e1lise cr\u00edtica do artigo \"Evaluation of attention-based LSTM and Bi-LSTM networks for abstract text classification in systematic literature review automation\".</p> <p>O trabalho se insere no contexto de automa\u00e7\u00e3o de Revis\u00f5es Sistem\u00e1ticas da Literatura (RSL), mais especificamente na etapa de triagem de resumos (abstract screening), que representa um dos principais gargalos em termos de esfor\u00e7o humano. Foram realizadas atividades que incluem a an\u00e1lise te\u00f3rica do artigo, a constru\u00e7\u00e3o de um pipeline experimental baseado no modelo proposto pelos autores, a coleta e prepara\u00e7\u00e3o das bases de dados p\u00fablicas dispon\u00edveis, bem como a avalia\u00e7\u00e3o quantitativa dos resultados obtidos em compara\u00e7\u00e3o com os relatados originalmente.</p> <p>Al\u00e9m disso, parte das descobertas ser\u00e3o incorporadas aos cap\u00edtulos da disserta\u00e7\u00e3o em andamento, com destaque para a fundamenta\u00e7\u00e3o te\u00f3rica (Cap\u00edtulo 2), descri\u00e7\u00e3o da metodologia (Cap\u00edtulo 4), estudos de caso (Cap\u00edtulo 5) e estrutura\u00e7\u00e3o inicial da an\u00e1lise de resultados (Cap\u00edtulo 6). O relat\u00f3rio tamb\u00e9m descreve os principais obst\u00e1culos enfrentados na reprodutibilidade dos experimentos e apresenta os pr\u00f3ximos passos para aprofundar a calibra\u00e7\u00e3o de modelos e a amplia\u00e7\u00e3o dos testes.</p>"},{"location":"reports/status/status_report_2025_06_29/#descricao-das-atividades-realizadas","title":"Descri\u00e7\u00e3o das Atividades Realizadas","text":"<p>As atividades realizadas foram:</p> <ol> <li>Estudo detalhado do artigo \"Artigo Evaluation of attention-based LSTM and Bi-LSTM networks for abstract text classification in systematic literature review automation\"<ul> <li>Identificar o problema que o artigo resolve</li> <li>Identificar o m\u00e9todo utilizado</li> <li>Identificar as m\u00e9tricas utilizadas</li> </ul> </li> <li>Fazer uma primeira an\u00e1lise experimental dos resultados<ul> <li>Busca das bases de dados necess\u00e1rias</li> <li>Busca se h\u00e1 necessidade de pr\u00e9-processamento</li> <li>Tentar replicar o m\u00e1ximo poss\u00edvel os resultados</li> </ul> </li> <li>Adicionar informa\u00e7\u00f5es na tese de mestrado<ul> <li>Cap\u00edtulo 2 (Fundamenta\u00e7\u00e3o Te\u00f3rica)</li> <li>Cap\u00edtulo 4 (M\u00e9todo Proposto)</li> <li>Cap\u00edtulo 5 (Estudos de Caso)</li> <li>Cap\u00edtulo 6 (An\u00e1lise e Discuss\u00e3o de Resultados)</li> </ul> </li> </ol> <p>Observa\u00e7\u00e3o Cap\u00edtulo 6</p> <p>O caso do Cap\u00edtulo 6 seria apenas montar o esqueleto dos resultados</p>"},{"location":"reports/status/status_report_2025_06_29/#experimentosestudos-realizados","title":"Experimentos/Estudos Realizados","text":""},{"location":"reports/status/status_report_2025_06_29/#fundamentacao-e-objetivos","title":"Fundamenta\u00e7\u00e3o e Objetivos","text":"<p>O artigo analisado prop\u00f5e automatizar a etapa de triagem de resumos (abstract screening) no processo de Revis\u00e3o Sistem\u00e1tica (Systematic Review - SR), que \u00e9 considerada a mais onerosa. Para isso, foram explorados modelos de Deep Learning como <code>LSTM</code> e <code>Bi-LSTM</code> com embeddings <code>GloVe</code> e mecanismos de aten\u00e7\u00e3o.</p> <p>Dois principais objetivos norteiam o trabalho: 1. Avaliar a viabilidade de usar modelos <code>LSTM</code> e <code>Bi-LSTM</code>, comparando-os com m\u00e9todos tradicionais como <code>SVM + TF-IDF</code>; 2. Investigar se o uso de mecanismos de aten\u00e7\u00e3o melhora a precis\u00e3o sem comprometer o recall, buscando manter este \u00faltimo em &gt;= 95%.</p>"},{"location":"reports/status/status_report_2025_06_29/#metodologia-implementada","title":"Metodologia Implementada","text":"<ul> <li>Bases de dados: Foram utilizadas seis bases de dados de revis\u00f5es sistem\u00e1ticas (5 p\u00fablicas e 1 privada). Apenas as p\u00fablicas foram usadas no experimento.</li> <li>Pr\u00e9-processamento: Tokeniza\u00e7\u00e3o, remo\u00e7\u00e3o de pontua\u00e7\u00e3o e stopwords. Lemmatiza\u00e7\u00e3o/stemming foram evitados para n\u00e3o perder informa\u00e7\u00e3o sem\u00e2ntica importante.</li> <li>Vetoriza\u00e7\u00e3o: Utilizou-se GloVe com 300 dimens\u00f5es, considerando o tamanho m\u00e9dio dos resumos.</li> <li>Modelos testados:<ul> <li>LSTM + GloVe</li> <li>Bi-LSTM + GloVe</li> <li>LSTM + GloVe + Attention</li> <li>Bi-LSTM + GloVe + Attention</li> </ul> </li> <li>T\u00e9cnica de balanceamento: Aprendizado sens\u00edvel a custo (cost-sensitive learning) usando pesos proporcionais ao desbalanceamento entre classes.</li> <li>Avalia\u00e7\u00e3o: 5-fold cross-validation com m\u00e9tricas: Precision, Recall, F2-score e WSS@95.</li> </ul>"},{"location":"reports/status/status_report_2025_06_29/#metricas-de-avaliacao","title":"M\u00e9tricas de Avalia\u00e7\u00e3o","text":"<ul> <li>Precision: TP / (TP + FP)</li> <li>Recall: TP / (TP + FN)</li> <li>F2-Score: (5 * P * R) / (4 * (P + R))</li> <li>WSS@95: Quantifica o esfor\u00e7o economizado ao atingir 95% de recall \u2014 m\u00e9trica cr\u00edtica em SRs.</li> </ul>"},{"location":"reports/status/status_report_2025_06_29/#resultados-experimentais-parciais","title":"Resultados Experimentais Parciais","text":"<p>Foi poss\u00edvel executar a replica\u00e7\u00e3o parcial dos experimentos com os modelos propostos. Os primeiros testes foram feitos com a base Appenzeller-Herzog 2020, utilizando a arquitetura <code>Bi-LSTM</code> com e sem aten\u00e7\u00e3o. O pipeline envolveu:</p> <ul> <li>Treinamento com batch size 64, 10 epochs;</li> <li>Otimiza\u00e7\u00e3o com Adam (lr = 3e-4 para LSTM, 1e-4 para Bi-LSTM);</li> <li>Dropout aplicados para evitar overfitting;</li> <li>Predi\u00e7\u00e3o com limiar calibrado para recall &gt;= 95%.</li> </ul> <p>Resultados num\u00e9ricos e gr\u00e1ficos de precis\u00e3o vs. recall foram extra\u00eddos do notebook e servir\u00e3o como base para os cap\u00edtulos da disserta\u00e7\u00e3o.</p>"},{"location":"reports/status/status_report_2025_06_29/#estudo-detalhado-do-artigo-evaluation-of-attention-based-lstm-and-bi-lstm-networks-for-abstract-text-classification-in-systematic-literature-review-automation","title":"Estudo Detalhado do \"Artigo Evaluation of attention-based LSTM and Bi-LSTM networks for abstract text classification in systematic literature review automation\"","text":"<p>O primeiro passo realizado foi um estudo aprofundado no artigo Artigo Evaluation of attention-based LSTM and Bi-LSTM networks for abstract text classification in systematic literature review automation a fim de obter informa\u00e7\u00f5es mais detalhadas sobre as bases para o Cap\u00edtulo 2 (Fundamenta\u00e7\u00e3o Te\u00f3rica), Cap\u00edtulo 4 (M\u00e9todo Proposto), Cap\u00edtulo 5 (Estudos de Caso) e Cap\u00edtulo 6 (An\u00e1lise e Discuss\u00e3o de Resultados).</p> <p>O Fluxo executado pelo artigo envolve a utiliza\u00e7\u00e3o de 6 bases de dados, sendo 1 privada e 5 p\u00fablicas. As 7 bases de dados foram enriquecidas usando metodologias descritas pelos pr\u00f3prios autores. A base de dados original SYNERGY dataset e a base de dados enriquecida com anos recentes Systematic Review Datasets.</p> <p>Cada base de dados possui os artigos inclusos e exclu\u00eddos (presente na coluna <code>label_included</code>). Para a base de dados enriquecida, tem-se a seguinte compara\u00e7\u00e3o separada por base:</p> \u00cdndice Nome do conjunto de dados T\u00f3pico Inclu\u00eddos Exclu\u00eddos IR (inclu\u00eddo:exclu\u00eddo) 1 Aceves-Martins2021 (AM)* Sa\u00fade Bucal 18 789 1:44 2 Appenzeller-Herzog 2020 (AH) Doen\u00e7a de Wilson 29 3424 1:118 3 Bannach-Brown 2019 (BB) Modelo Animal de Depress\u00e3o 280 1713 1:6 4 Cohen ACEInhibitors 2006 (CACE) Antipsic\u00f3ticos at\u00edpicos 146 974 1:7 5 Cohen AtypicalAntipsychotics 2006 (CAA) ACE Inhibitors 41 2503 1:61 6 Cohen OralHypoglycemics 2006 (COH) Hipoglicemiantes orais 136 367 1:3 <p>Observa\u00e7\u00e3o base de dados Aceves-Martins2021 (AM)*</p> <p>A base de dados Aceves-Martins2021 (AM) n\u00e3o ser\u00e1 usada para os experimentos devido a falta de acesso a ela na internet. Com isso, para a tese de mestrado, ser\u00e1 usada somente as p\u00fablicas.</p> <p>Ap\u00f3s o enriquecimento das bases de dados, foi separado apenas as informa\u00e7\u00f5es <code>{abstract, label_included}</code> de cada conjunto. O <code>abstract</code> foi tokenizado e depois mapeado usando o arquivo do Glove de 300 dimens\u00f5es para obter uma matriz com vetores densos.</p> <p>No artigo, o treinamento ocorreu segundo os hiperpar\u00e2metros</p> Hiperpar\u00e2metro Value Embedding dimension 300 LSTM units 100 Bi-LSTM unitss 100 Optimiser Adam Learning rate (optimiser) 3 * 10^(-4) for LSTM Learning rate (optimiser) 3 * 10^(-4) for Bi-LSTM Dropout for LSTM 0.2, 0.5 Dropout for Bi-LSTM 0.2, 0.02 Batch size 64 Epochs 10 <p>O artigo utilizou-se de dois experimentos. O primeiro com <code>SVM</code>, <code>LSTM + Glove</code> e <code>Bi-LSTM + Glove</code>. O segundo foi <code>LSTM + Glove + Attention</code> e <code>Bi-LSTM + Glove + Attention</code>.</p> <p></p> <p>Com isso, cada base de dados foi submetida a uma simula\u00e7\u00e3o e ao final foi realizado um cross validation com os modelos j\u00e1 treinados. Ao final, foram obtidos as m\u00e9tricas:</p> <ul> <li>TP: True Positives \u2014 exemplos positivos corretamente classificados como positivos</li> <li>FP: False Positives \u2014 exemplos negativos incorretamente classificados como positivos</li> <li>TN: True Negatives \u2014 exemplos negativos corretamente classificados como negativos</li> <li>FN: False Negatives \u2014 exemplos positivos incorretamente classificados como negativos</li> <li>N: Number of Negatives \u2014 total de exemplos negativos no conjunto (geralmente: TN + FP)</li> <li>P: Precision \u2014 propor\u00e7\u00e3o de positivos preditos que s\u00e3o realmente positivos: P = TP/(TP + FP)</li> <li>R: Recall \u2014 taxa de verdadeiros positivos: R = TP/(TP + FN)</li> <li>F2: F2-Score \u2014 m\u00e9trica F que d\u00e1 mais peso ao recall (peso 2): F2 = 5 * P * R / (4 * (P + R))</li> </ul>"},{"location":"reports/status/status_report_2025_06_29/#resultados-obtidos","title":"Resultados Obtidos","text":"<p>Os resultados obtidos foram os presentes na tabela abaixo:</p> Dataset Classifier TP_gerado FP_gerado TN_gerado FN_gerado N P_gerado R_gerado F2_gerado WSS95_gerado TP_pdf FP_pdf TN_pdf FN_pdf P_pdf R_pdf F2_pdf WSS95_pdf erro_P erro_R erro_F2 erro_WSS95 Appenzeller-Herzog_2020 SVM with SGD + TF-IDF 26 2333 0 0 2333 0.0110216 1 0.0527812 -0.05 5 4423 329 468 0.0117 1 0.0558 4.28 0.000678381 0 0.00301884 4.33 Appenzeller-Herzog_2020 SVM with SGD + TF-IDF 26 2333 0 0 2333 0.0110216 1 0.0527812 -0.05 5 4423 329 468 0.0117 1 0.0558 4.28 0.000678381 0 0.00301884 4.33 Appenzeller-Herzog_2020 Bi-LSTM + GloVe 26 2333 0 0 2333 0.0110216 1 0.0527812 -0.05 4 27044 138 239 0.015 0.9615 0.0705 24.25 0.00397838 0.0385 0.0177188 24.3 Appenzeller-Herzog_2020 Bi-LSTM + GloVe + Attention 26 2333 0 0 2333 0.0110216 1 0.0527812 -0.05 4 472 0 0 0.0215 0.9615 0.0986 45.66 0.0104784 0.0385 0.0458188 45.71 Appenzeller-Herzog_2020 LSTM + GloVe 26 2333 0 0 2333 0.0110216 1 0.0527812 -0.05 5 1980 0 0 0.0081 1 0.039 -5 0.00292162 0 0.0137812 4.95 Appenzeller-Herzog_2020 LSTM + GloVe + Attention 26 2333 0 0 2333 0.0110216 1 0.0527812 -0.05 5 472 0 0 0.0132 0.9474 0.0623 37.01 0.00217838 0.0526 0.00951884 37.06 <p>Os valores obtidos nas r\u00e9plicas apresentaram desvios em rela\u00e7\u00e3o aos relatados no artigo, especialmente nas m\u00e9tricas de WSS@95 e F2, que s\u00e3o sens\u00edveis ao balanceamento de classes e aos thresholds de corte aplicados nos classificadores. Esses desvios indicam que os hiperpar\u00e2metros utilizados nos modelos reproduzidos podem n\u00e3o estar completamente ajustados conforme o artigo original, o que justifica novos experimentos de calibra\u00e7\u00e3o.</p>"},{"location":"reports/status/status_report_2025_06_29/#problemas-encontrados","title":"Problemas Encontrados","text":"<ul> <li>Resultados obtidos nos experimentos divergiram dos reportados no artigo original, especialmente nos valores de FP, WSS e F2-score.</li> <li>Diferen\u00e7as podem ser atribu\u00eddas a:<ul> <li>Uso de thresholds padr\u00e3o ao inv\u00e9s dos calibrados para Recall &gt;= 95%.</li> <li>Configura\u00e7\u00f5es de dropout e learning rate n\u00e3o exatas.</li> <li>Potencial diferen\u00e7a na amostragem ou divis\u00e3o dos folds de cross-validation.</li> </ul> </li> <li>Falta de reprodutibilidade total por aus\u00eancia de c\u00f3digo-fonte oficial dos autores.</li> </ul>"},{"location":"reports/status/status_report_2025_06_29/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ul> <li>Escrever cap\u00edtulos restantes da disserta\u00e7\u00e3o baseado nos experimentos<ul> <li>Cap\u00edtulo 2: Modelos utilizados</li> <li>Cap\u00edtulo 3: Filtrar artigos importantes</li> <li>Cap\u00edtulo 4: Descrever a metodologia aplicada</li> <li>Cap\u00edtulo 5: Descrever os experimentos</li> </ul> </li> <li>Implementar um estudo sistem\u00e1tico de hiperpar\u00e2metros (com grid search ou optuna)</li> <li>Calibrar thresholds baseados no recall de 95% antes do c\u00e1lculo das m\u00e9tricas</li> <li>Redigir um RFC (Request for Comments) interno sobre:<ul> <li>A expans\u00e3o dos experimentos (novos modelos e datasets)</li> <li>Estrat\u00e9gias para an\u00e1lise de sensibilidade dos hiperpar\u00e2metros</li> </ul> </li> <li>Automatizar o pipeline de avalia\u00e7\u00e3o e compara\u00e7\u00e3o com benchmarks de artigos</li> </ul>"},{"location":"rfcs/","title":"Defini\u00e7\u00e3o RFC","text":"<p>Um RFC (Request for Comments, ou \"Pedido de Coment\u00e1rios\") \u00e9 um documento t\u00e9cnico que descreve especifica\u00e7\u00f5es, propostas ou padr\u00f5es relacionados a sistemas computacionais, projetos de software, ou processos organizacionais. \u00c9 amplamente utilizado em comunidades de software livre, grupos de pesquisa, empresas de tecnologia e desenvolvimento colaborativo para registrar e discutir decis\u00f5es de projeto antes de implement\u00e1-las.</p>"},{"location":"rfcs/#para-que-serve-um-rfc","title":"Para que serve um RFC?","text":"<p>O principal objetivo de um RFC \u00e9:</p> <ul> <li>Formalizar uma proposta de mudan\u00e7a ou adi\u00e7\u00e3o significativa a um sistema ou projeto.</li> <li>Registrar o racioc\u00ednio por tr\u00e1s de decis\u00f5es t\u00e9cnicas.</li> <li>Promover discuss\u00e3o aberta e transparente entre membros da equipe ou comunidade.</li> <li>Servir como documenta\u00e7\u00e3o hist\u00f3rica e refer\u00eancia futura.</li> </ul> <p>RFCs ajudam a evitar decis\u00f5es arbitr\u00e1rias ou mal documentadas, criando um registro claro das inten\u00e7\u00f5es, implica\u00e7\u00f5es e alternativas consideradas.</p>"},{"location":"rfcs/#estrutura-comum-de-um-rfc","title":"Estrutura comum de um RFC","text":"<p>Embora a estrutura possa variar conforme o projeto ou organiza\u00e7\u00e3o, uma RFC geralmente segue o seguinte modelo:</p> <ol> <li>T\u00edtulo: Um nome claro e descritivo para a proposta.</li> <li>Resumo (Abstract): Um par\u00e1grafo curto explicando o objetivo da RFC.</li> <li>Motiva\u00e7\u00e3o (Motivation): Por que essa mudan\u00e7a \u00e9 necess\u00e1ria? Que problema resolve?</li> <li>Proposta / Detalhes T\u00e9cnicos (Proposal): Descri\u00e7\u00e3o detalhada da solu\u00e7\u00e3o proposta.</li> <li>Alternativas consideradas: Outras solu\u00e7\u00f5es que foram avaliadas e descartadas.</li> <li>Impacto / Compatibilidade: Implica\u00e7\u00f5es pr\u00e1ticas, riscos ou compatibilidade com vers\u00f5es anteriores.</li> <li>Implementa\u00e7\u00e3o: Considera\u00e7\u00f5es sobre como a mudan\u00e7a ser\u00e1 implementada (se aplic\u00e1vel).</li> <li>Conclus\u00e3o: Resumo final e pr\u00f3ximos passos.</li> <li>Refer\u00eancias: Fontes e materiais relacionados.</li> <li>Hist\u00f3rico de revis\u00e3o (Changelog): Atualiza\u00e7\u00f5es e edi\u00e7\u00f5es feitas no documento.</li> </ol>"},{"location":"rfcs/#exemplo-de-uso-no-mestrado","title":"Exemplo de uso no mestrado","text":"<p>No contexto de um projeto de mestrado, RFCs podem ser usados para:</p> <ul> <li>Propor e documentar escolhas metodol\u00f3gicas (ex: \"Uso de modelo transformer para classifica\u00e7\u00e3o\").</li> <li>Especificar mudan\u00e7as na organiza\u00e7\u00e3o dos dados ou na arquitetura experimental.</li> <li>Discutir novos fluxos de trabalho ou ferramentas adotadas.</li> </ul>"},{"location":"rfcs/#beneficios","title":"Benef\u00edcios","text":"<ul> <li>Melhor colabora\u00e7\u00e3o entre orientador, colegas e revisores.</li> <li>Transpar\u00eancia nas decis\u00f5es.</li> <li>Facilidade para retomar discuss\u00f5es t\u00e9cnicas ap\u00f3s pausas longas.</li> <li>Registro formal e rastre\u00e1vel das decis\u00f5es do projeto.</li> </ul>"},{"location":"rfcs/#referencias","title":"Refer\u00eancias","text":"<ul> <li>IETF RFC Editor \u2014 Base oficial de RFCs da Internet (ex: TCP/IP, HTTP, etc.)</li> <li>GitHub RFC Process \u2013 Rust Language \u2014 Exemplo real de uso de RFCs em projeto open-source.</li> <li>Documenting Architecture Decisions \u2014 Conceito relacionado: ADRs (Architecture Decision Records).</li> </ul>"},{"location":"rfcs/files/0001_experiments/","title":"Expans\u00e3o dos Experimentos com Transformers, Embeddings Contextuais e Aprendizado Ativo","text":""},{"location":"rfcs/files/0001_experiments/#resumo","title":"Resumo","text":"<p>Este RFC prop\u00f5e a expans\u00e3o metodol\u00f3gica do projeto de mestrado por meio da introdu\u00e7\u00e3o de modelos Transformer pr\u00e9-treinados (como BioBERT e SciBERT), vetoriza\u00e7\u00e3o com embeddings contextualizados (ex: SBERT), e avalia\u00e7\u00e3o com t\u00e9cnicas de aprendizado ativo. O objetivo \u00e9 atualizar o pipeline experimental para refletir o estado da arte em triagem automatizada de Revis\u00f5es Sistem\u00e1ticas da Literatura (RSL), especialmente em tarefas de classifica\u00e7\u00e3o bin\u00e1ria com alto desbalanceamento de classes e restri\u00e7\u00e3o de recall.</p>"},{"location":"rfcs/files/0001_experiments/#motivacao","title":"Motiva\u00e7\u00e3o","text":"<p>A literatura recente (2021\u20132025) mostra que modelos baseados em Transformers superam arquiteturas como LSTM e Bi-LSTM em tarefas de classifica\u00e7\u00e3o de textos cient\u00edficos. Al\u00e9m disso, o uso de embeddings contextualizados e estrat\u00e9gias de aprendizado ativo tem demonstrado ganhos substanciais em recall, WSS@95 e economia de esfor\u00e7o humano.</p> <p>Essa expans\u00e3o se justifica pelos seguintes pontos:</p> <ul> <li>Resultados inconsistentes ao tentar replicar os experimentos do artigo base com LSTM.</li> <li>Exist\u00eancia de ferramentas p\u00fablicas (ASReview, HuggingFace) que oferecem suporte direto a Transformers e Active Learning.</li> <li>A necessidade de investigar a aplicabilidade de m\u00e9todos mais recentes e robustos.</li> </ul>"},{"location":"rfcs/files/0001_experiments/#proposta","title":"Proposta","text":""},{"location":"rfcs/files/0001_experiments/#1-modelos-a-serem-testados","title":"1. Modelos a serem testados","text":"<p>BioBERT: modelo BERT pr\u00e9-treinado com literatura biom\u00e9dica (PubMed).</p> <ul> <li><code>SciBERT</code>: modelo BERT treinado com textos cient\u00edficos (Semantic Scholar).</li> <li><code>PubMedBERT</code>: modelo treinado do zero com corpus PubMed.</li> <li><code>Sentence-BERT</code>: vers\u00e3o de BERT para embeddings de senten\u00e7as.</li> </ul> <p>Cada modelo ser\u00e1 <code>fine-tuned</code> para a tarefa bin\u00e1ria de inclus\u00e3o/exclus\u00e3o de resumos.</p>"},{"location":"rfcs/files/0001_experiments/#2-estrategias-de-vetorizacao-adicionais","title":"2. Estrat\u00e9gias de vetoriza\u00e7\u00e3o adicionais","text":"<ul> <li><code>SBERT embeddings + SVM/XGBoost</code>: avalia\u00e7\u00e3o do uso de embeddings de senten\u00e7a como entrada para modelos tradicionais.</li> <li>Compara\u00e7\u00e3o com GloVe, TF-IDF e FastText.</li> </ul>"},{"location":"rfcs/files/0001_experiments/#3-aprendizado-ativo","title":"3. Aprendizado Ativo","text":"<p>Avalia\u00e7\u00e3o de desempenho com simula\u00e7\u00f5es de triagem ativa (CAL).</p> <p>Estrat\u00e9gias:</p> <ul> <li>Uncertainty sampling (baseado em entropia/softmax)<ul> <li>Random sampling (baseline)</li> <li>Core-set selection (caso vi\u00e1vel)</li> </ul> </li> <li>Ferramenta sugerida: ASReview LAB (https://asreview.nl/)</li> </ul>"},{"location":"rfcs/files/0001_experiments/#4-calibracao-de-thresholds","title":"4. Calibra\u00e7\u00e3o de Thresholds","text":"<ul> <li>Ajuste de thresholds com base em:<ul> <li>Curvas Precision-Recall</li> <li>Platt Scaling</li> <li>Isotonic Regression</li> </ul> </li> <li>Foco em calibrar para Recall \u2265 95%.</li> </ul>"},{"location":"rfcs/files/0001_experiments/#5-novas-metricas-a-coletar","title":"5. Novas m\u00e9tricas a coletar","text":"<ul> <li><code>WSS@95</code> (Work Saved over Sampling at 95% Recall)</li> <li><code>AUROC</code>, <code>PR-AUC</code>, tempo de infer\u00eancia</li> <li>Simula\u00e7\u00e3o de triagem (n\u00famero de resumos lidos at\u00e9 atingir 95% de recall)</li> </ul>"},{"location":"rfcs/files/0001_experiments/#alternativas-consideradas","title":"Alternativas Consideradas","text":"<ul> <li>Continuar com LSTM apenas: descartado por limita\u00e7\u00e3o emp\u00edrica e estado da arte defasado.</li> <li>Apenas usar Transformers sem aprendizado ativo: descartado por n\u00e3o capturar o comportamento real da triagem humana assistida por IA.</li> </ul>"},{"location":"rfcs/files/0001_experiments/#impacto-compatibilidade","title":"Impacto / Compatibilidade","text":"<ul> <li>Impacto positivo: maior robustez dos resultados e alinhamento com a pr\u00e1tica cient\u00edfica atual.</li> <li>Compatibilidade: plenamente compat\u00edvel com o pipeline atual. A vetoriza\u00e7\u00e3o e modelos novos podem ser adicionados modularmente.</li> </ul>"},{"location":"rfcs/files/0001_experiments/#implementacao","title":"Implementa\u00e7\u00e3o","text":"<ul> <li>Usar <code>HuggingFace Transformers</code> para fine-tuning de modelos BERT.</li> <li>Integrar <code>sentence-transformers</code> para SBERT.</li> <li>Empacotar o pipeline com scripts reprodut\u00edveis para cada experimento.</li> <li>Utilizar ASReview LAB para experimentos com aprendizado ativo.</li> </ul>"},{"location":"rfcs/files/0001_experiments/#conclusao","title":"Conclus\u00e3o","text":"<p>Esta RFC formaliza a proposta de moderniza\u00e7\u00e3o do pipeline experimental do projeto de mestrado, com foco em Transformer models, embeddings contextuais e aprendizado ativo. A implementa\u00e7\u00e3o dessas melhorias est\u00e1 alinhada com o estado da arte e deve aumentar a validade e a relev\u00e2ncia dos resultados obtidos.</p>"},{"location":"rfcs/files/0001_experiments/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Beltagy, I. et al. (2019). BioBERT.</li> <li>Lee, J. et al. (2020). PubMedBERT.</li> <li>Devlin, J. et al. (2018). BERT.</li> <li>Reimers, N., Gurevych, I. (2019). Sentence-BERT.</li> <li>Van de Schoot, R. et al. (2021). ASReview: Open-source tool for screening in SRs.</li> <li>https://asreview.nl/</li> <li>https://huggingface.co/models</li> </ul>"},{"location":"study/0001_text_classification_techniques/","title":"T\u00e9cnicas de Classifica\u00e7\u00e3o de Textos","text":"<p>A classifica\u00e7\u00e3o de textos \u00e9 uma tarefa fundamental no campo do Processamento de Linguagem Natural (PLN), com aplica\u00e7\u00f5es que v\u00e3o desde filtros de spam at\u00e9 an\u00e1lise de sentimentos e detec\u00e7\u00e3o de t\u00f3picos. Essa tarefa consiste em atribuir um ou mais r\u00f3tulos a um dado texto, com base em seu conte\u00fado.</p>"},{"location":"study/0001_text_classification_techniques/#tipos-de-formas-de-classificacao","title":"Tipos de Formas de Classifica\u00e7\u00e3o","text":"Classifica\u00e7\u00e3o Exemplo de classes Exemplo pr\u00e1tico Classifica\u00e7\u00e3o bin\u00e1ria <code>[0, 1]</code> Detectar se um e-mail \u00e9 spam ou n\u00e3o Multi-classifica\u00e7\u00e3o <code>[0, 1, 2]</code> Classificar opini\u00f5es: positivo, neutro, negativo Classifica\u00e7\u00e3o multilabel <code>[[0, 1], [1, 2]]</code> Um filme pode ser rotulado como a\u00e7\u00e3o e aventura <ul> <li>Classifica\u00e7\u00e3o bin\u00e1ria \u00e9 o caso mais simples, com apenas duas categorias.</li> <li>Multi-classifica\u00e7\u00e3o envolve m\u00faltiplas categorias mutuamente exclusivas.</li> <li>Classifica\u00e7\u00e3o multilabel permite que um mesmo texto perten\u00e7a a m\u00faltiplas categorias simultaneamente (Tsoumakas &amp; Katakis, 2007).</li> </ul>"},{"location":"study/0001_text_classification_techniques/#tecnicas-de-chaveamento-pipeline","title":"T\u00e9cnicas de Chaveamento (Pipeline)","text":"<p>O processo de classifica\u00e7\u00e3o de textos geralmente segue um pipeline composto pelas seguintes etapas:</p> <ol> <li> <p>Texto cru    Entrada textual bruta, como not\u00edcias, avalia\u00e7\u00f5es, posts em redes sociais, etc.</p> </li> <li> <p>Extra\u00e7\u00e3o de caracter\u00edsticas (Feature Extraction)    Convers\u00e3o do texto em vetores num\u00e9ricos utiliz\u00e1veis por modelos de aprendizado de m\u00e1quina. As t\u00e9cnicas incluem:</p> <ul> <li>Bag of Words (BoW) </li> <li>TF-IDF (Term Frequency - Inverse Document Frequency) </li> <li>Word Embeddings (ex: Word2Vec, GloVe, FastText) </li> <li>Embeddings contextualizados (ex: BERT, RoBERTa)    (Jurafsky &amp; Martin, 2021)</li> </ul> </li> <li> <p>Modelo de Classifica\u00e7\u00e3o    O modelo aprende a associar padr\u00f5es de entrada com os r\u00f3tulos corretos. Exemplos:</p> <ul> <li>Regress\u00e3o log\u00edstica</li> <li>Naive Bayes</li> <li>Support Vector Machines (SVM)</li> <li>Redes Neurais (LSTM, CNN, Transformers)    (Sebastiani, 2002)</li> </ul> </li> <li> <p>Sa\u00edda / Infer\u00eancia    O modelo gera um ou mais r\u00f3tulos como sa\u00edda. Em modelos probabil\u00edsticos, pode-se usar thresholds para decidir a classe mais prov\u00e1vel.</p> </li> </ol>"},{"location":"study/0001_text_classification_techniques/#boas-praticas","title":"Boas Pr\u00e1ticas","text":"<ol> <li> <p>Balanceamento de Dados    Classes desbalanceadas podem prejudicar o desempenho do modelo. T\u00e9cnicas como oversampling, undersampling e uso de m\u00e9tricas adequadas como F1-score s\u00e3o recomendadas.</p> </li> <li> <p>Desambigua\u00e7\u00e3o Sem\u00e2ntica    Palavras com m\u00faltiplos significados (ex: \u201cbanco\u201d) exigem contexto. Modelos como BERT melhoram a capacidade de desambiguar automaticamente usando aten\u00e7\u00e3o contextual (Devlin et al., 2019).</p> </li> <li> <p>Diversidade e Qualidade dos Dados    Os dados de treinamento devem refletir a variedade de textos presentes no ambiente real de aplica\u00e7\u00e3o (ex: varia\u00e7\u00f5es lingu\u00edsticas, g\u00edrias, erros ortogr\u00e1ficos). Dados enviesados podem gerar modelos injustos.</p> </li> <li> <p>Avalia\u00e7\u00e3o Robusta    Usar valida\u00e7\u00e3o cruzada, m\u00e9tricas como acur\u00e1cia, precis\u00e3o, recall e F1-score, al\u00e9m de dividir os dados em conjuntos de treino, valida\u00e7\u00e3o e teste.</p> </li> </ol>"},{"location":"study/0001_text_classification_techniques/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805.</li> <li>Jurafsky, D., &amp; Martin, J. H. (2021). Speech and Language Processing (3rd ed. draft). Stanford University.</li> <li>Sebastiani, F. (2002). Machine learning in automated text categorization. ACM Computing Surveys (CSUR), 34(1), 1\u201347.</li> <li>Tsoumakas, G., &amp; Katakis, I. (2007). Multi-label classification: An overview. International Journal of Data Warehousing and Mining (IJDWM), 3(3), 1\u201313.</li> </ul>"}]}